{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "9b659b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "from math import factorial\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "615322aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ex 1. Crude monte carlo simulator\n",
    "\n",
    "def confidence_interval(confidence, means, point_estimate):\n",
    "    std_error = stats.sem(means)\n",
    "    return stats.t.interval(confidence, df=len(means)-1, loc=point_estimate, scale=std_error)\n",
    "\n",
    "\n",
    "def crude_monte_carlo(integral_range: tuple, samples: int, func):\n",
    "    a, b = integral_range\n",
    "    return func(a, b, samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ec4033ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exercise 1:\n",
      "Point estimate: 1.7317128301304363\n",
      "Confidence interval: (1.63298, 1.83044)\n"
     ]
    }
   ],
   "source": [
    "# mean of integral of e^x from 0 to 1\n",
    "integral_range = (0,1)\n",
    "samples = 100\n",
    "f = lambda a, b, samples: np.exp(np.random.uniform(a, b, samples))\n",
    "X = crude_monte_carlo(integral_range, samples, f)\n",
    "\n",
    "X_point_estimate = np.mean(X)\n",
    "ci = confidence_interval(0.95, X, X_point_estimate)\n",
    "print(\"Exercise 1:\")\n",
    "print(\"Point estimate:\", X_point_estimate)\n",
    "print(f\"Confidence interval: ({ci[0]:.5f}, {ci[1]:.5f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c83ec64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2\n",
    "def antithetic_variables(integral_range, samples):\n",
    "    Ui = np.random.uniform(low=integral_range[0], high=integral_range[1], size=samples)\n",
    "    Y = (np.exp(Ui) + np.exp(1-Ui)) / 2\n",
    "    return np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f40ed759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exercise 2:\n",
      "Point estimate: 1.7134401999183921\n",
      "Confidence interval: (1.69617, 1.73071)\n"
     ]
    }
   ],
   "source": [
    "Y = antithetic_variables(integral_range, samples//2)\n",
    "\n",
    "Y_point_estimate = np.mean(Y)\n",
    "ci = confidence_interval(0.95, Y, Y_point_estimate)\n",
    "print(\"Exercise 2:\")\n",
    "print(\"Point estimate:\", Y_point_estimate)\n",
    "print(f\"Confidence interval: ({ci[0]:.5f}, {ci[1]:.5f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ffc5faee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3\n",
    "def control_variate(X, Y, mean_y):\n",
    "    c = -np.cov(X, Y, ddof=1)[0][1] / np.var(Y, ddof=1)\n",
    "    Z = X + c * (Y - mean_y)\n",
    "    var_Z = np.var(X, ddof=1) - np.cov(X,Y, ddof=1)[0][1] ** 2 / np.var(Y, ddof=1)\n",
    "    return Z, var_Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8b92365f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exercise 3 with variables from slides:\n",
      "Z: 1.6517829572307585\n",
      "Var(Z): 0.0030492941868425216\n"
     ]
    }
   ],
   "source": [
    "# Example from slides\n",
    "U = np.random.uniform(0, 1, samples)\n",
    "Z, var_Z = control_variate(np.exp(U), U, np.mean(U))\n",
    "\n",
    "Z_point_estimate = np.mean(Z)\n",
    "print(\"Exercise 3 with variables from slides:\")\n",
    "print(\"Z:\", Z_point_estimate)\n",
    "print(f\"Var(Z):\", var_Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5491cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_sampling(samples, n_strata):\n",
    "    samples_per_stratum = samples // n_strata\n",
    "    i = np.arange(n_strata)\n",
    "    \n",
    "    U = np.random.uniform(0, 1, (n_strata, samples_per_stratum))\n",
    "    Y = (i[:, None] + U) / n_strata \n",
    "    W = np.exp(Y)\n",
    "    \n",
    "    return W, Y\n",
    "\n",
    "n_strata = 10\n",
    "W, Y = stratified_sampling(samples, n_strata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a0e55255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exercise 4:\n",
      "Stratified sampling mean: 1.7167698726833693\n",
      "Number of strata: 10\n"
     ]
    }
   ],
   "source": [
    "print(\"Exercise 4:\")\n",
    "print(f\"Stratified sampling mean: {np.mean(W)}\")\n",
    "print(f\"Number of strata: {n_strata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e4be82e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5 stratified sampling using control variates\n",
    "def stratified_sampling_with_cv(samples, n_strata):\n",
    "    samples_per_stratum = samples // n_strata\n",
    "    i = np.arange(n_strata)\n",
    "    stratum_means = (i + 0.5) / n_strata\n",
    "    \n",
    "    U = np.random.uniform(0, 1, (n_strata, samples_per_stratum))\n",
    "    Y = (i[:, None] + U) / n_strata \n",
    "    W = np.exp(Y)\n",
    "\n",
    "    Z = np.zeros_like(W)\n",
    "    stratum_variances = np.zeros(n_strata)\n",
    "    \n",
    "    for k in range(n_strata):\n",
    "        cov = np.cov(W[k], Y[k])[0, 1]\n",
    "        var_y = np.var(Y[k])\n",
    "        c = -cov / var_y\n",
    "        \n",
    "        Z[k] = W[k] + c * (Y[k] - stratum_means[k])\n",
    "        stratum_variances[k] = np.var(Z[k]) / samples_per_stratum\n",
    "\n",
    "    total_variance = np.sum(stratum_variances) / (n_strata**2)\n",
    "    \n",
    "    return Z, total_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0a7684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exercise 5: \n",
      "W: 1.7179554803491837\n",
      "Var(W): 3.1731706092141887e-07\n"
     ]
    }
   ],
   "source": [
    "# Exercise 5\n",
    "Z, var_Z = stratified_sampling_with_cv(samples, n_strata)\n",
    "\n",
    "print('Exercise 5: ')\n",
    "print(\"Z:\", np.mean(Z))\n",
    "print(\"Var(Z):\", var_Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "74202894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Exact Erlang B (Poisson)': 0.1216610642529515,\n",
      " 'WITH CRN': {'95% CI': (-0.024875844032046807, -0.018964155967953197),\n",
      "              'Mean Difference (Poisson - Hyper)': -0.021920000000000002,\n",
      "              'Var of Difference': 0.004769066994706615},\n",
      " 'WITHOUT CRN': {'95% CI': (-0.023810134295119176, -0.015929865704880815),\n",
      "                 'Mean Difference (Poisson - Hyper)': -0.019869999999999995,\n",
      "                 'Var of Difference': 0.006357156946658191}}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from math import factorial\n",
    "\n",
    "# Parameters\n",
    "m = 10  \n",
    "mean_service_time = 8\n",
    "mean_interarrival_time = 1\n",
    "num_runs = 10\n",
    "customers_per_run = 10000\n",
    "total_customers = num_runs * customers_per_run\n",
    "\n",
    "\n",
    "def erlang_b_formula(A, m):\n",
    "    inv_b = sum((A**k) / factorial(k) for k in range(m + 1))\n",
    "    return (A**m) / factorial(m) / inv_b\n",
    "\n",
    "# Hyperexponential params\n",
    "p = 0.5\n",
    "lambda1 = 2.0 \n",
    "lambda2 = 2/3  \n",
    "\n",
    "def generate_hyperexponential(size):\n",
    "    choices = np.random.rand(size)\n",
    "    return np.where(choices < p,\n",
    "                    np.random.exponential(scale=1/lambda1, size=size),\n",
    "                    np.random.exponential(scale=1/lambda2, size=size))\n",
    "\n",
    "def simulate(arrival_times, service_times):\n",
    "    service_end_times = []\n",
    "    blocked = 0\n",
    "\n",
    "    for arrival, service in zip(arrival_times, service_times):\n",
    "        service_end_times = [t for t in service_end_times if t > arrival]\n",
    "        if len(service_end_times) < m:\n",
    "            service_end_times.append(arrival + service)\n",
    "        else:\n",
    "            blocked += 1\n",
    "\n",
    "    return blocked / customers_per_run\n",
    "\n",
    "# Simulate without CRN\n",
    "diffs_no_crn = []\n",
    "\n",
    "for _ in range(num_runs):\n",
    "    service_times_poisson = np.random.exponential(scale=mean_service_time, size=customers_per_run)\n",
    "    service_times_hyper = np.random.exponential(scale=mean_service_time, size=customers_per_run)\n",
    "\n",
    "    poisson_interarrivals = np.random.exponential(scale=mean_interarrival_time, size=customers_per_run)\n",
    "    hyper_interarrivals = generate_hyperexponential(customers_per_run)\n",
    "\n",
    "    arrival_poisson = np.cumsum(poisson_interarrivals)\n",
    "    arrival_hyper = np.cumsum(hyper_interarrivals)\n",
    "\n",
    "    blocked_poisson = simulate(arrival_poisson, service_times_poisson)\n",
    "    blocked_hyper = simulate(arrival_hyper, service_times_hyper)\n",
    "\n",
    "    diffs_no_crn.append(blocked_poisson - blocked_hyper)\n",
    "diffs_crn = []\n",
    "\n",
    "for run in range(num_runs):\n",
    "    np.random.seed(run)  # CRN seed for each run\n",
    "\n",
    "    service_times = np.random.exponential(scale=mean_service_time, size=customers_per_run)\n",
    "    uniform_stream = np.random.rand(customers_per_run)\n",
    "\n",
    "    poisson_interarrivals = -np.log(1 - uniform_stream) * mean_interarrival_time\n",
    "    arrival_poisson = np.cumsum(poisson_interarrivals)\n",
    "\n",
    "    choice = uniform_stream\n",
    "    alt_uniform = np.random.rand(customers_per_run)  \n",
    "    hyper_interarrivals = np.where(\n",
    "        choice < p,\n",
    "        -np.log(alt_uniform) / lambda1,\n",
    "        -np.log(alt_uniform) / lambda2\n",
    "    )\n",
    "    arrival_hyper = np.cumsum(hyper_interarrivals)\n",
    "\n",
    "    blocked_poisson = simulate(arrival_poisson, service_times)\n",
    "    blocked_hyper = simulate(arrival_hyper, service_times)\n",
    "    diffs_crn.append(blocked_poisson - blocked_hyper)\n",
    "\n",
    "mean_diff_no_crn = np.mean(diffs_no_crn)\n",
    "var_no_crn = np.var(diffs_no_crn, ddof=1)\n",
    "ci_no_crn = norm.interval(0.95, loc=mean_diff_no_crn, scale=std_diff_no_crn / np.sqrt(num_runs))\n",
    "\n",
    "mean_diff_crn = np.mean(diffs_crn)\n",
    "var_crn = np.var(diffs_crn, ddof=1)\n",
    "ci_crn = norm.interval(0.95, loc=mean_diff_crn, scale=std_diff_crn / np.sqrt(num_runs))\n",
    "\n",
    "result = {\n",
    "    \"WITHOUT CRN\": {\n",
    "        \"Mean Difference (Poisson - Hyper)\": mean_diff_no_crn,\n",
    "        \"Var of Difference\": std_diff_no_crn,\n",
    "        \"95% CI\": ci_no_crn\n",
    "    },\n",
    "    \"WITH CRN\": {\n",
    "        \"Mean Difference (Poisson - Hyper)\": mean_diff_crn,\n",
    "        \"Var of Difference\": std_diff_crn,\n",
    "        \"95% CI\": ci_crn\n",
    "    },\n",
    "    \"Exact Erlang B (Poisson)\": B_exact\n",
    "}\n",
    "\n",
    "pprint.pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "571e6b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6954205049839229"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_crn / var_no_crn - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1352c5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 7\n",
    "from scipy.stats import norm\n",
    "\n",
    "mu = 0\n",
    "sigma_2 = 1\n",
    "samples = 100\n",
    "a = 2\n",
    "\n",
    "crude_monte_carlo = lambda mu, sigma, samples: np.random.normal(mu, sigma, samples)\n",
    "\n",
    "\n",
    "def importance_sampling(a, sigma, samples):\n",
    "    f = lambda x: norm.pdf(x)\n",
    "    g = lambda x: norm.pdf(x, loc=a, scale=sigma)\n",
    "    \n",
    "    g_samples = np.random.normal(a, sigma, samples)\n",
    "    \n",
    "    weights = f(g_samples) / g(g_samples)\n",
    "    h = (g_samples > a).astype(float)\n",
    "    \n",
    "    estimate = np.mean(h * weights)\n",
    "    variance = np.var(h * weights) / samples\n",
    "    \n",
    "    return estimate, variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "931a1a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crude monte carlo:\n",
      "===============================\n",
      "Odds of Z > a where a=0: 0.51\n",
      "Variance: 0.0024989999999999995\n",
      "===============================\n",
      "Odds of Z > a where a=1: 0.15\n",
      "Variance: 0.001275\n",
      "===============================\n",
      "Odds of Z > a where a=2: 0.04\n",
      "Variance: 0.00038399999999999996\n",
      "===============================\n",
      "Odds of Z > a where a=3: 0.01\n",
      "Variance: 9.9e-05\n",
      "===============================\n",
      "Odds of Z > a where a=4: 0.0\n",
      "Variance: 0.0\n",
      "===============================\n"
     ]
    }
   ],
   "source": [
    "# Exercise 7\n",
    "Z = crude_monte_carlo(mu, sigma_2, samples)\n",
    "print(\"Crude monte carlo:\")\n",
    "for a in [0, 1, 2, 3, 4]:\n",
    "    print(\"===============================\")\n",
    "    print(f\"Odds of Z > a where a={a}: {(Z>a).mean()}\")\n",
    "    print(\"Variance:\", (Z>a).var() / samples)\n",
    "print(\"===============================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "8eecf487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Odds of Z > a where a=0 and sigma_2 = 1: 0.51\n",
      "Variance: 0.0024989999999999995\n",
      "===============================\n",
      "Odds of Z > a where a=0 and sigma_2 = 2: 0.47183432257284375\n",
      "Variance: 0.004332750054263219\n",
      "===============================\n",
      "Odds of Z > a where a=0 and sigma_2 = 3: 0.45202891037230164\n",
      "Variance: 0.007671797510444788\n",
      "===============================\n",
      "Odds of Z > a where a=1 and sigma_2 = 1: 0.1519475364927777\n",
      "Variance: 0.0004078230649432278\n",
      "===============================\n",
      "Odds of Z > a where a=1 and sigma_2 = 2: 0.18297639297409685\n",
      "Variance: 0.0011308404724020159\n",
      "===============================\n",
      "Odds of Z > a where a=1 and sigma_2 = 3: 0.1662841721478388\n",
      "Variance: 0.00150146891596583\n",
      "===============================\n",
      "Odds of Z > a where a=2 and sigma_2 = 1: 0.022129269144666078\n",
      "Variance: 1.1260365677980657e-05\n",
      "===============================\n",
      "Odds of Z > a where a=2 and sigma_2 = 2: 0.02609550854135541\n",
      "Variance: 3.4641585783224095e-05\n",
      "===============================\n",
      "Odds of Z > a where a=2 and sigma_2 = 3: 0.03131464784283799\n",
      "Variance: 6.201495844782132e-05\n",
      "===============================\n",
      "Odds of Z > a where a=3 and sigma_2 = 1: 0.001085850433735574\n",
      "Variance: 3.4846004140637864e-08\n",
      "===============================\n",
      "Odds of Z > a where a=3 and sigma_2 = 2: 0.0012309185253518394\n",
      "Variance: 8.955282247498607e-08\n",
      "===============================\n",
      "Odds of Z > a where a=3 and sigma_2 = 3: 0.001163204385926083\n",
      "Variance: 1.4380216453980247e-07\n"
     ]
    }
   ],
   "source": [
    "for a in range(4):\n",
    "    for sigma in range(1,4):\n",
    "        estimate, variance = importance_sampling(a, sigma, samples)\n",
    "        print(\"===============================\")\n",
    "        print(f\"Odds of Z > a where a={a} and sigma_2 = {sigma}: {estimate}\")\n",
    "        print(\"Variance:\", variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "6cf2d50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 8\n",
    "def importance_sampling_exp(samples, _lambda):\n",
    "    Y = np.random.exponential(scale=1/_lambda, size=samples)\n",
    "    W = np.exp(Y) / (_lambda * np.exp(-_lambda * Y))\n",
    "    estimate = np.mean(W * (Y <= 1))\n",
    "    variance = np.var(W * (Y <= 1)) / samples\n",
    "    return estimate, variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "a73b65e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal lambda ~ 1.3 gives estimate 1.7138690991558068, with variance 6.37383254671174e-06\n"
     ]
    }
   ],
   "source": [
    "optimal_lambda = None\n",
    "lowest_var = np.inf\n",
    "\n",
    "# Find best lambda\n",
    "for _lambda in np.arange(0.1,3,0.1):\n",
    "    est, var = importance_sampling_exp(1000000, _lambda)\n",
    "    if var < lowest_var:\n",
    "        lowest_var = var\n",
    "        optimal_lambda = _lambda\n",
    "\n",
    "print(f\"Optimal lambda ~ {optimal_lambda} gives estimate {est}, with variance {var}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning_ex_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
