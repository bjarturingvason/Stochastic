{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "9b659b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615322aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ex 1. Crude monte carlo simulator\n",
    "\n",
    "def confidence_interval(confidence, means, point_estimate):\n",
    "    std_error = stats.sem(means)\n",
    "    return stats.t.interval(confidence, df=len(means)-1, loc=point_estimate, scale=std_error)\n",
    "\n",
    "\n",
    "def crude_monte_carlo(integral_range: tuple, samples: int, func):\n",
    "    a = integral_range[0]\n",
    "    b = integral_range[1]\n",
    "    return func(a, b, samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "ec4033ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exercise 1:\n",
      "Point estimate: 1.7191003845599324\n",
      "Confidence interval: (1.71814, 1.72007)\n"
     ]
    }
   ],
   "source": [
    "# mean of integral of e^x from 0 to 1\n",
    "integral_range = (0,1)\n",
    "samples = 1000000\n",
    "f = lambda a, b, samples: np.exp(np.random.uniform(a, b, samples))\n",
    "X = crude_monte_carlo(integral_range, samples, f)\n",
    "\n",
    "X_point_estimate = np.mean(X)\n",
    "ci = confidence_interval(0.95, X, X_point_estimate)\n",
    "print(\"Exercise 1:\")\n",
    "print(\"Point estimate:\", X_point_estimate)\n",
    "print(f\"Confidence interval: ({ci[0]:.5f}, {ci[1]:.5f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c83ec64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2\n",
    "def antithetic_variables(integral_range, samples):\n",
    "    Ui = np.random.uniform(low=integral_range[0], high=integral_range[1], size=samples)\n",
    "    Y = (np.exp(Ui) + np.exp(1-Ui)) / 2\n",
    "    return np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "f40ed759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exercise 2:\n",
      "Point estimate: 1.7176279216909203\n",
      "Confidence interval: (1.71371, 1.72155)\n"
     ]
    }
   ],
   "source": [
    "Y = antithetic_variables(integral_range, samples)\n",
    "\n",
    "Y_point_estimate = np.mean(Y)\n",
    "ci = confidence_interval(0.95, Y, Y_point_estimate)\n",
    "print(\"Exercise 2:\")\n",
    "print(\"Point estimate:\", Y_point_estimate)\n",
    "print(f\"Confidence interval: ({ci[0]:.5f}, {ci[1]:.5f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ffc5faee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3\n",
    "def control_variate(X, Y, mean_y):\n",
    "    # Z = X + c * (Y - mu_y)\n",
    "    c = -np.cov(X, Y)[0][1] / np.var(Y)\n",
    "    Z = X + c * (Y - mean_y)\n",
    "    var_Z = np.var(X) - np.cov(X,Y)[0][1] ** 2 / np.var(X)\n",
    "    return Z, var_Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "8b92365f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exercise 3 with variables from slides:\n",
      "Z: 1.695360029209771\n",
      "Var(Z): 0.1485920324192506\n"
     ]
    }
   ],
   "source": [
    "# Example from slides\n",
    "U = np.random.uniform(0, 1, 1000)\n",
    "Z, var_Z = control_variate(np.exp(U), U, np.mean(U))\n",
    "\n",
    "Z_point_estimate = np.mean(Z)\n",
    "print(\"Exercise 3 with variables from slides:\")\n",
    "print(\"Z:\", Z_point_estimate)\n",
    "print(f\"Var(Z):\", var_Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "fa38b10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4\n",
    "def stratified_sampling(U, samples):\n",
    "    i = np.arange(samples)\n",
    "    W = np.exp((i + U) / samples).mean(axis=1)\n",
    "    return W\n",
    "\n",
    "dimension = int(np.sqrt(samples))\n",
    "U = np.random.normal(0,1, [dimension, dimension])\n",
    "W = stratified_sampling(U, dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "a0e55255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exercise 4:\n",
      "Stratified sampling mean: 1.7174249172468627\n"
     ]
    }
   ],
   "source": [
    "print(\"Exercise 4:\")\n",
    "print(f\"Stratified sampling mean: {np.mean(W)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "4b0a7684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exercise 5: \n",
      "W: 1.7174263430809455\n",
      "Var(W): -0.00035022083237356573\n"
     ]
    }
   ],
   "source": [
    "# Exercise 5\n",
    "W, var_W = control_variate(W, np.random.uniform(0, 1, int(np.sqrt(samples))), 1/2)\n",
    "\n",
    "print('Exercise 5: ')\n",
    "print(\"W:\", np.mean(W))\n",
    "print(\"Var(W):\", var_W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5eb2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 6\n",
    "def stratified_sampling_with_cv(U, samples):\n",
    "    i = np.arange(samples)[:,None]\n",
    "    x = (i + U) / samples\n",
    "\n",
    "    f = np.exp(x)\n",
    "    g = x\n",
    "\n",
    "    g_mean = (i + 1/2) / samples\n",
    "\n",
    "    cov_fg = np.array([np.cov(f[k], g[k])[0, 1] for k in range(samples)])\n",
    "    var_g = np.var(g, axis=1)\n",
    "    c = -cov_fg / var_g\n",
    "    \n",
    "    Z = f + c[:, None] * (g - g_mean)\n",
    "    \n",
    "    stratum_estimates = Z.mean(axis=1)\n",
    "    stratum_variances = np.var(Z, axis=1, ddof=1) / U.shape[1]\n",
    "    \n",
    "    integral_estimate = stratum_estimates.sum() / samples\n",
    "    total_variance = stratum_variances.sum() / (samples ** 2)\n",
    "    \n",
    "    return integral_estimate, total_variance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c07d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate: 1.718258 (True = 1.718282)\n",
      "Variance: 7.006e-10\n"
     ]
    }
   ],
   "source": [
    "K = 10 \n",
    "n_k = 100\n",
    "U = np.random.random((K, n_k))\n",
    "\n",
    "estimate, variance = stratified_sampling_with_cv(U, K)\n",
    "\n",
    "print('Exercise 5')\n",
    "print(f\"Estimate: {estimate:.6f} (True = {np.exp(1)-1:.6f})\")\n",
    "print(f\"Variance: {variance:.3e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "1352c5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 7\n",
    "f = lambda a, b, samples: np.random.normal(a, b, samples)\n",
    "a = 2\n",
    "sigma_2 = 1\n",
    "samples = 1000\n",
    "\n",
    "def crude_monte_carlo(integral_range: tuple, samples: int, func):\n",
    "    a = integral_range[0]\n",
    "    b = integral_range[1]\n",
    "    return func(a, b, samples)\n",
    "\n",
    "Z = crude_monte_carlo((0,1), 1000, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "931a1a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Odds of Z > a: 0.025\n",
      "Variance: 2.4374999999999996e-05\n"
     ]
    }
   ],
   "source": [
    "# Exercise 7\n",
    "print(\"Odds of Z > a:\", (Z>a).mean())\n",
    "print(\"Variance:\", (X>a).var() / samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "08ed71c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For a = 2:\n",
      "Crude MC: P(Z>2) = 0.023100, Var = 2.26e-06\n",
      "Importance Sampling: P(Z>2) = 0.022592, Var = 8.40e-07\n",
      "Variance reduction: 62.8%\n",
      "\n",
      "For a = 4:\n",
      "Crude MC: P(Z>4) = 0.000000, Var = 0.00e+00\n",
      "Importance Sampling: P(Z>4) = 0.000032, Var = 4.66e-13\n",
      "Variance reduction: -inf%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rl/wmw8y4kx7nl7flgwk7c8y81h0000gp/T/ipykernel_70952/2707125559.py:25: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  print(f\"Variance reduction: {100*(var-var_is)/var:.1f}%\")\n"
     ]
    }
   ],
   "source": [
    "def importance_sampling(a, n_samples=10000, shift_mean=a, shift_var=1):\n",
    "    \"\"\"Importance sampling estimator for P(Z > a)\"\"\"\n",
    "    # Sample from shifted normal\n",
    "    Y = np.random.normal(loc=shift_mean, scale=np.sqrt(shift_var), size=n_samples)\n",
    "    # Calculate importance weights\n",
    "    f = norm.pdf(Y)  # Standard normal PDF\n",
    "    g = norm.pdf(Y, loc=shift_mean, scale=np.sqrt(shift_var))  # Proposal PDF\n",
    "    h = (Y > a).astype(float)\n",
    "    W = h * f / g\n",
    "    return np.mean(W), np.var(W)/n_samples\n",
    "\n",
    "# Experiment for different a values\n",
    "for a in [2, 4]:\n",
    "    print(f\"\\nFor a = {a}:\")\n",
    "    # Crude MC\n",
    "    f = lambda mu, sigma, samples: np.random.normal(mu, sigma, samples)\n",
    "    Z = crude_monte_carlo((0,1), 10000, f)\n",
    "    est = (Z>a).mean()\n",
    "    var = (Z>a).var() / 10000\n",
    "    print(f\"Crude MC: P(Z>{a}) = {est:.6f}, Var = {var:.2e}\")\n",
    "    \n",
    "    # Importance sampling\n",
    "    est_is, var_is = importance_sampling(a)\n",
    "    print(f\"Importance Sampling: P(Z>{a}) = {est_is:.6f}, Var = {var_is:.2e}\")\n",
    "    print(f\"Variance reduction: {100*(var-var_is)/var:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "4c95e8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimal lambda: 0.50\n",
      "IS estimate: 1.706005, True value: 1.718282\n",
      "Variance: 1.45e-04\n"
     ]
    }
   ],
   "source": [
    "# Exercise 8\n",
    "def importance_sampling_exp(n_samples=10000, lambd=1):\n",
    "    \"\"\"Importance sampling with exponential proposal\"\"\"\n",
    "    # Sample from exponential\n",
    "    Y = np.random.exponential(scale=1/lambd, size=n_samples)\n",
    "    # Only keep samples in [0,1]\n",
    "    Y = Y[Y <= 1]\n",
    "    if len(Y) == 0:\n",
    "        return 0, 0  # Edge case when lambda is too large\n",
    "    \n",
    "    # Calculate weights\n",
    "    f = 1  # Uniform PDF\n",
    "    g = lambd * np.exp(-lambd * Y)  # Exponential PDF\n",
    "    h = np.exp(Y)\n",
    "    W = h * f / g\n",
    "    \n",
    "    # Correct for truncation to [0,1]\n",
    "    correction = 1 - np.exp(-lambd)  # P(Y ≤ 1)\n",
    "    return np.mean(W) * correction, np.var(W)/len(Y) * correction**2\n",
    "\n",
    "# Find optimal lambda by minimizing variance\n",
    "lambdas = np.linspace(0.1, 10, 50)\n",
    "variances = []\n",
    "for l in lambdas:\n",
    "    _, var = importance_sampling_exp(lambd=l)\n",
    "    variances.append(var)\n",
    "    \n",
    "optimal_lambda = lambdas[np.argmin(variances)]\n",
    "print(f\"\\nOptimal lambda: {optimal_lambda:.2f}\")\n",
    "\n",
    "# Compare with true integral (e^1 - e^0 ≈ 1.71828)\n",
    "est, var = importance_sampling_exp(lambd=optimal_lambda)\n",
    "print(f\"IS estimate: {est:.6f}, True value: {np.exp(1)-1:.6f}\")\n",
    "print(f\"Variance: {var:.2e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stochastic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
